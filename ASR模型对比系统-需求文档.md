# ASR 语音识别模型对比系统 - 需求文档

## 1. 项目概述

### 1.1 项目背景
开发一个前端页面，用于实时对比展示两个语音识别（ASR）模型的识别结果，使用户能够直观地比较个人专属模型（`xu_zhuxi_model`）与基础模型（`base_model`）在相同音频输入下的识别差异。

### 1.2 项目目标
- 提供友好的用户界面，支持音频上传和实时录制
- 同时调用两个模型进行语音识别
- 以直观的方式展示两个模型的识别结果对比
- 突出显示两个模型识别结果的差异部分

---

## 2. 功能需求

### 2.1 音频输入模块

#### 2.1.1 音频上传功能
- **功能描述**: 支持用户上传本地音频文件
- **支持格式**: 
  - MP3 (.mp3)
  - WAV (.wav)
  - 其他常见音频格式
- **文件大小限制**: 建议限制在 25MB 以内
- **界面要求**: 
  - 拖拽上传区域
  - 点击选择文件按钮
  - 显示已上传文件名称和时长

#### 2.1.2 实时录制功能
- **功能描述**: 支持用户使用麦克风实时录制音频
- **界面要求**:
  - "开始录制"和"停止录制"按钮
  - 录制状态指示（录制中/已停止）
  - 录制时长显示
  - 录制波形可视化（可选）

#### 2.1.3 音频播放功能
- **功能描述**: 上传/录制后支持预览播放
- **界面要求**:
  - 音频播放器控件（播放/暂停、进度条、音量控制）
  - 播放速度调节（0.5x ~ 2.0x）

---

### 2.2 模型调用模块

#### 2.2.1 后端 API 接口
**基准模型接口 (base_model)**
- **接口路径**: `/api/v1/asr/base-model`
- **请求方式**: POST
- **输入**: 音频文件或音频 URL
- **输出**: 识别文本、置信度分数、可能的时间戳信息

**个人专属模型接口 (xu_zhuxi_model)**
- **接口路径**: `/api/v1/asr/personal-model`
- **请求方式**: POST
- **输入**: 音频文件或音频 URL
- **输出**: 识别文本、置信度分数、可能的时间戳信息

#### 2.2.2 模型配置
- **SenseVoiceSmall 模型路径**:
  - 基准模型: `/root/demo_1_confidence/base_model/SenseVoiceSmall/`
  - 个人专属模型: `/root/demo_1_confidence/xu_zhuxi_model/SenseVoiceSmall/`
- **VAD 模型路径**:
  - `/root/demo_1_confidence/base_model/speech_fsmn_vad_zh-cn-16k-common-pytorch/`
- **推理配置**:
  - 支持中文、英文、日语、韩语、粤语识别
  - 采样率: 16kHz

#### 2.2.3 调用流程
1. 前端将音频文件发送到后端
2. 后端调用模型进行语音识别
3. 返回识别结果（包括文本和置信度）
4. 记录调用耗时

---

### 2.3 结果展示模块

#### 2.3.1 对比展示布局
**双栏对比设计**:
```
+----------------------------------------------------------+
|  音频播放器                                                |
+----------------------------------------------------------+
|                          |                                |
|  个人专属模型               |   基准模型                     |
|  (xu_zhuxi_model)         |   (base_model)                |
|                          |                                |
|  [识别结果文本]            |   [识别结果文本]               |
|                          |                                |
|  置信度: XX.XX%          |   置信度: XX.XX%               |
|  耗时: XXX ms            |   耗时: XXX ms                 |
|                          |                                |
+----------------------------------------------------------+
|  差异对比区（高亮显示不同之处）                            |
+----------------------------------------------------------+
```

#### 2.3.2 识别结果卡片
每个模型的识别结果需展示以下信息：
- **识别文本**: 模型输出的文字结果
- **置信度**: 模型对识别结果的置信度分数（百分比）
- **处理耗时**: 从发送到返回结果的时间（毫秒）
- **音频片段**: 对应的时间戳（可选）

#### 2.3.3 差异对比功能
- **自动检测差异**: 标注两个模型识别结果的不同之处
- **高亮显示**: 使用不同颜色标记差异部分
- **差异类型**:
  - 文本完全相同（绿色标识）
  - 部分内容不同（黄色标识）
  - 完全不同（红色标识）

#### 2.3.4 统计信息
- **差异统计面板**:
  - 相似度百分比
  - 相同字数 / 不同字数
  - Word Error Rate (WER) - 可选

---

### 2.4 交互功能

#### 2.4.1 快捷操作
- [重新识别] 按钮：清空结果后重新处理
- [交换结果] 按钮：左右模型位置互换（可选）
- [导出报告] 按钮：下载对比结果（JSON/CSV格式）

#### 2.4.2 历史记录
- 保存用户上传/录制的历史记录
- 支持快速重新对比历史音频
- 本地存储（localStorage）或后端存储

---

## 3. 非功能需求

### 3.1 性能需求
- 音频识别响应时间 < 10秒（25MB以内音频）
- 前端页面加载时间 < 3秒
- 支持并发请求处理

### 3.2 兼容性需求
- **浏览器支持**: Chrome、Firefox、Safari、Edge 最新版本
- **移动端适配**: 响应式设计，支持手机和平板访问
- **音频格式兼容**: 跨浏览器音频播放兼容性处理

### 3.3 安全性需求
- 文件上传安全校验（文件类型、大小）
- 防止恶意文件上传
- API 访问权限控制（可选）

### 3.4 可用性需求
- 清晰的错误提示信息
- 加载状态指示器
- 操作撤销/重试功能
- 无障碍访问支持（WCAG 2.1 AA）

---

## 4. 技术架构

### 4.1 前端技术栈（建议）
- **框架**:  Vue.js
- **UI 组件库**: Ant Design / Element Plus
- **音频处理**: Web Audio API / Howler.js
- **样式**: CSS3 / Tailwind CSS
- **HTTP 请求**: Axios

### 4.2 后端技术栈（建议）
- **框架**: FastAPI / Flask
- **ASR 模型**: WeFunnel / SenseVoiceSmall
- **音频处理**: torchaudio / librosa
- **部署**: Docker / Kubernetes

### 4.3 部署架构
```
[用户浏览器]
    ↓ HTTPS
[反向代理 Nginx]
    ↓
[Web 服务器 / API 服务器]
    ↓
[模型推理服务]
    ├── 基准模型 (base_model)
    └── 个人专属模型 (xu_zhuxi_model)
```

---

## 5. 界面原型描述

### 5.1 首页布局
1. **顶部导航栏**: 项目标题、模型状态指示
2. **主内容区**:
   - 左侧：音频上传/录制区
   - 右侧：音频播放器预览
3. **对比结果区**: 两个模型识别结果并排展示
4. **底部**: 统计信息和操作按钮

### 5.2 配色方案
- **主色调**: 深蓝色（专业感）
- **基准模型**: 蓝色边框
- **个人专属模型**: 绿色边框（强调个性化）
- **差异高亮**: 黄色背景
- **相同部分**: 绿色背景

---

## 6. 项目里程碑

### 阶段 1: 基础功能开发
- [ ] 完成音频上传和录制功能
- [ ] 完成基础模型调用接口
- [ ] 完成识别结果展示页面

### 阶段 2: 增强功能开发
- [ ] 完成两个模型同时调用和对比
- [ ] 实现差异检测和高亮显示
- [ ] 添加置信度展示

### 阶段 3: 优化和完善
- [ ] 性能优化（加载速度、响应时间）
- [ ] 移动端适配
- [ ] 用户体验优化
- [ ] 添加历史记录功能

---

## 7. 验收标准

### 功能验收
- [ ] 用户可以上传音频文件并成功识别
- [ ] 用户可以使用麦克风录制音频并成功识别
- [ ] 页面同时展示两个模型的识别结果
- [ ] 两个模型识别结果有明显的差异高亮
- [ ] 置信度和处理耗时信息正确显示

### 性能验收
- [ ] 页面加载时间 < 3秒
- [ ] 10秒内音频识别完成
- [ ] 界面操作流畅无卡顿

### 兼容性验收
- [ ] Chrome 浏览器测试通过
- [ ] Firefox 浏览器测试通过
- [ ] 移动端响应式布局正常

---

## 8. 风险评估

| 风险项 | 风险等级 | 应对措施 |
|--------|----------|----------|
| 模型推理时间过长 | 中 | 添加加载动画，优化模型配置 |
| 音频格式兼容性 | 低 | 提供格式转换工具 |
| 大文件上传失败 | 中 | 分片上传、断点续传 |
| 浏览器兼容性 | 低 | 渐进式增强，使用 polyfill |

---

## 9. 附录

### 9.1 模型文件结构
```
base_model/
├── SenseVoiceSmall/
│   ├── model.pt          # 模型权重
│   ├── config.yaml       # 配置文件
│   ├── tokens.json       # 词表文件
│   ├── chn_jpn_yue_eng_ko_spectok.bpe.model  # BPE模型
│   └── example/          # 示例音频
└── speech_fsmn_vad_zh-cn-16k-common-pytorch/
    ├── model.pt          # VAD模型
    └── config.yaml       # VAD配置

xu_zhuxi_model/
└── [同上结构 - 已微调的模型]
```

### 9.2 参考资料
- SenseVoiceSmall 官方文档
- Web Audio API 文档
- ASR 评估指标说明（WER, CER）

---

**文档版本**: v1.0
**创建日期**: 2026-02-05
**文档状态**: 草稿
