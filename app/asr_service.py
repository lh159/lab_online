import os
import re
import time
from typing import List, Dict, Any, Optional
from funasr import AutoModel
from funasr.utils.postprocess_utils import rich_transcription_postprocess


class ASRService:
    """
    å°è£… ASR æ¨ç†é€»è¾‘ï¼Œæ”¯æŒä¸¤ä¸ªæ¨¡å‹ï¼š
    - base_model: åŸºç¡€æ¨¡å‹ï¼Œæœªç»ä¸ªæ€§åŒ–å¾®è°ƒ
    - personal_model: ä¸ªäººä¸“å±æ¨¡å‹ï¼ˆxu_zhuxi_modelï¼‰
    
    æä¾› transcribe() è¿”å›è¯†åˆ«æ–‡æœ¬åŠæŒ‰å¥/è¯çš„ç½®ä¿¡åº¦ä¿¡æ¯ã€‚
    """

    def __init__(self,
                 base_model_path: str = "/root/demo_1_confidence/base_model/SenseVoiceSmall",
                 personal_model_path: str = "/root/demo_1_confidence/xu_zhuxi_model/SenseVoiceSmall",
                 device: str = "cuda:0"):
        self.base_model_path = base_model_path
        self.personal_model_path = personal_model_path
        self.device = device
        self.model_base = None
        self.model_personal = None
        self._load_models()

    def _load_models(self):
        print("ASRService: loading models...")
        load_start = time.time()
        
        # åŠ è½½åŸºç¡€æ¨¡å‹
        print(f"  Loading base model from: {self.base_model_path}")
        self.model_base = AutoModel(
            model=self.base_model_path,
            trust_remote_code=False,
            vad_model=None,
            vad_kwargs={"max_single_segment_time": 30000},
            device=self.device,
        )
        print(f"  Base model loaded in {time.time() - load_start:.2f}s")
        
        # åŠ è½½ä¸ªäººä¸“å±æ¨¡å‹
        personal_load_start = time.time()
        print(f"  Loading personal model from: {self.personal_model_path}")
        self.model_personal = AutoModel(
            model=self.personal_model_path,
            trust_remote_code=False,
            vad_model=None,
            vad_kwargs={"max_single_segment_time": 30000},
            device=self.device,
        )
        print(f"  Personal model loaded in {time.time() - personal_load_start:.2f}s")
        print("ASRService: all models loaded successfully!")

    def _postprocess_text(self, text: str) -> str:
        text = rich_transcription_postprocess(text)
        # æ¸…ç†å¸¸è§ emoji
        for e in ["ğŸ˜Š", "ğŸ¼", "ğŸ˜”"]:
            text = text.replace(e, "")
        return text

    def _split_sentences(self, text: str) -> List[str]:
        # ç®€å•æŒ‰ä¸­æ–‡å’Œè‹±æ–‡å¥æœ«ç¬¦å·åˆ†å¥ï¼Œä¿ç•™æ ‡ç‚¹
        parts = re.split(r'([ã€‚ï¼ï¼Ÿ!?]+)', text)
        sentences = []
        for i in range(0, len(parts) - 1, 2):
            sent = (parts[i] + parts[i + 1]).strip()
            if sent:
                sentences.append(sent)
        # å¤„ç†æœ«å°¾æ®‹ä½™
        if len(parts) % 2 == 1 and parts[-1].strip():
            sentences.append(parts[-1].strip())
        return sentences if sentences else [text]

    def _avg_conf(self, probs: List[float]) -> float:
        """
        æ›´å¥å£®åœ°è®¡ç®—å¹³å‡ç½®ä¿¡åº¦ã€‚æ”¯æŒå…ƒç´ ä¸ºæ•°å€¼æˆ–å­—å…¸çš„æƒ…å†µã€‚
        å­—å…¸ä¼šå°è¯•æŒ‰å¸¸è§å­—æ®µæå–æ•°å€¼ï¼š'prob','confidence','score','p','probability'ã€‚
        æ— æ³•è§£æçš„å…ƒç´ ä¼šè¢«è·³è¿‡ï¼›è‹¥æ‰€æœ‰å…ƒç´ æ— æ³•è§£æåˆ™è¿”å› 0.0ã€‚
        """
        if not probs:
            return 0.0
        return float(sum(probs) / len(probs))

    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªæ–‡æœ¬çš„ç›¸ä¼¼åº¦ï¼ˆåŸºäºç¼–è¾‘è·ç¦»ï¼‰
        è¿”å› 0-1 ä¹‹é—´çš„ç›¸ä¼¼åº¦åˆ†æ•°
        """
        if not text1 and not text2:
            return 1.0
        if not text1 or not text2:
            return 0.0
        
        # ç®€å•çš„å­—ç¬¦çº§ç›¸ä¼¼åº¦è®¡ç®—
        set1 = set(text1)
        set2 = set(text2)
        
        if not set1 or not set2:
            return 0.0
        
        intersection = len(set1 & set2)
        union = len(set1 | set2)
        
        return intersection / union if union > 0 else 0.0

    def _calculate_wer(self, reference: str, hypothesis: str) -> float:
        """
        è®¡ç®— Word Error Rate (WER)
        ç®€åŒ–ç‰ˆæœ¬ï¼šåŸºäºç©ºæ ¼åˆ†è¯
        """
        ref_words = reference.split()
        hyp_words = hypothesis.split()
        
        if not ref_words:
            return 0.0 if not hyp_words else 1.0
        
        # ç®€å•çš„ç¼–è¾‘è·ç¦»è®¡ç®—
        m, n = len(ref_words), len(hyp_words)
        dp = [[0] * (n + 1) for _ in range(m + 1)]
        
        for i in range(m + 1):
            dp[i][0] = i
        for j in range(n + 1):
            dp[0][j] = j
            
        for i in range(1, m + 1):
            for j in range(1, n + 1):
                if ref_words[i-1] == hyp_words[j-1]:
                    dp[i][j] = dp[i-1][j-1]
                else:
                    dp[i][j] = 1 + min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1])
        
        return dp[m][n] / m if m > 0 else 0.0

    def transcribe(self, audio_path: str, model_type: str = "base") -> Dict[str, Any]:
        """
        å¯¹éŸ³é¢‘æ–‡ä»¶æ‰§è¡Œæ¨ç†ï¼Œè¿”å›ç»“æ„ï¼š
        {
          "text": "...",
          "sentences": [{"text": "...", "confidence": 0.95, "words": [{"text": "...","confidence":0.9}, ...]}, ...],
          "raw_prob": [...],
          "model_type": "base" | "personal",
          "processing_time_ms": 123.45
        }
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            model_type: "base" æˆ– "personal"
        """
        model = self.model_base if model_type == "base" else self.model_personal
        model_name = "base_model" if model_type == "base" else "xu_zhuxi_model"
        
        start_time = time.time()
        
        res = model.generate(
            input=audio_path,
            cache={},
            language="auto",
            use_itn=True,
            batch_size_s=60,
            merge_vad=True,
            merge_length_s=15,
        )
        
        processing_time = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        
        raw_text = res[0].get("text", "")
        raw_prob = res[0].get("prob", []) or []
        text = self._postprocess_text(raw_text)

        # å­—ç¬¦çº§æ¦‚ç‡é•¿åº¦å¯èƒ½ä¸ text ä¸ä¸€è‡´ï¼Œå®‰å…¨å¤„ç†
        char_probs = []
        # å…ˆå°† raw_prob ä¸­å¯èƒ½çš„ dict å…ƒç´ è½¬æ¢ä¸ºæ•°å€¼åˆ—è¡¨
        numeric_raw_prob: List[float] = []
        if raw_prob:
            # å¦‚æœ raw_prob çš„å…ƒç´ ä¸º dict æˆ–å¤æ‚ç»“æ„ï¼Œå°è¯•æå–æ•°å€¼
            converted = []
            for el in raw_prob:
                if isinstance(el, (int, float)):
                    converted.append(float(el))
                elif isinstance(el, dict):
                    # å°è¯•æå–å¸¸è§å­—æ®µ
                    v = None
                    for key in ("prob", "confidence", "score", "p", "probability"):
                        if key in el:
                            v = el[key]
                            break
                    if isinstance(v, (int, float)):
                        converted.append(float(v))
                    elif isinstance(v, list):
                        nums = [float(x) for x in v if isinstance(x, (int, float))]
                        converted.append(sum(nums) / len(nums) if nums else 0.0)
                    elif isinstance(v, dict):
                        found = None
                        for subkey in ("prob", "confidence", "score", "p", "probability"):
                            if subkey in v and isinstance(v[subkey], (int, float)):
                                found = float(v[subkey])
                                break
                        converted.append(found if found is not None else 0.0)
                    else:
                        converted.append(0.0)
                else:
                    try:
                        converted.append(float(el))
                    except Exception:
                        converted.append(0.0)

            # å¦‚æœ converted ä¸­å…¨éƒ¨ä¸º 0.0ï¼ˆæˆ–é•¿åº¦ä¸º0ï¼‰ï¼Œä¿ç•™åŸ raw_prob empty
            numeric_raw_prob = converted

        if len(numeric_raw_prob) == len(raw_text):
            # å‡è®¾ raw_prob ä¸ raw_text å¯¹åº”ï¼ˆæœ€å¸¸è§ï¼‰
            # æŠŠ raw_prob å¯¹é½åˆ°å¤„ç†å textï¼ˆç®€å•ç­–ç•¥ï¼šæˆªæ–­æˆ–ç”¨æœ€åå€¼å¡«å……ï¼‰
            if len(text) == len(raw_text):
                char_probs = numeric_raw_prob
            else:
                # å¤„ç†é•¿åº¦ä¸ç­‰æ—¶ï¼Œå°è¯•æŒ‰æ¯”ä¾‹æ˜ å°„
                if numeric_raw_prob:
                    scale = len(numeric_raw_prob) / max(1, len(text))
                    for i in range(len(text)):
                        idx = min(int(i * scale), len(numeric_raw_prob) - 1)
                        char_probs.append(numeric_raw_prob[idx])
        else:
            # fallback: å¦‚æœæ²¡æœ‰ prob æˆ–é•¿åº¦ä¸åŒ¹é…ï¼Œä½¿ç”¨å‡å€¼ 0.9ï¼ˆä¿å®ˆï¼‰
            if numeric_raw_prob:
                avg = self._avg_conf(numeric_raw_prob)
                char_probs = [avg] * len(text)
            elif raw_prob:
                # raw_prob å­˜åœ¨ä½†æ— æ³•è§£æä¸ºæ•°å€¼ï¼Œå°è¯•ä»åŸå§‹ç»“æ„å–å¹³å‡
                avg = self._avg_conf(raw_prob)
                char_probs = [avg] * len(text)
            else:
                char_probs = [0.9] * len(text)

        # åˆ†å¥å¹¶è®¡ç®—å¥å­ä¸è¯ç½®ä¿¡åº¦ï¼ˆæŒ‰å­—ç¬¦å¹³å‡ï¼‰
        sentences = []
        sent_boundaries = []
        # è®¡ç®—æ¯ä¸ªå¥å­çš„å­—ç¬¦èŒƒå›´ï¼ˆç®€å•æŒ‰åˆ†å¥å‡½æ•°ï¼‰
        sents = self._split_sentences(text)
        cursor = 0
        for s in sents:
            length = len(s)
            sent_probs = char_probs[cursor:cursor + length] if cursor + length <= len(char_probs) else char_probs[cursor:]
            sent_conf = self._avg_conf(sent_probs)
            # è¯çº§ï¼ˆç”¨ç©ºç™½åˆ†è¯ï¼‰
            words = []
            word_cursor = 0
            for w in s.split():
                wlen = len(w)
                w_probs = sent_probs[word_cursor:word_cursor + wlen] if word_cursor + wlen <= len(sent_probs) else sent_probs[word_cursor:]
                words.append({"text": w, "confidence": round(self._avg_conf(w_probs), 4)})
                word_cursor += wlen + 1  # +1 for the space removed by split (approx)
            sentences.append({"text": s, "confidence": round(sent_conf, 4), "words": words})
            cursor += length

        return {
            "text": text, 
            "sentences": sentences, 
            "raw_prob": raw_prob,
            "model_type": model_type,
            "model_name": model_name,
            "processing_time_ms": round(processing_time, 2)
        }

    def compare_models(self, audio_path: str) -> Dict[str, Any]:
        """
        åŒæ—¶è°ƒç”¨ä¸¤ä¸ªæ¨¡å‹è¿›è¡Œå¯¹æ¯”
        è¿”å›ä¸¤ä¸ªæ¨¡å‹çš„è¯†åˆ«ç»“æœå’Œç»Ÿè®¡åˆ†æ
        """
        # å¹¶è¡Œè°ƒç”¨ä¸¤ä¸ªæ¨¡å‹
        import asyncio
        
        async def run_comparison():
            loop = asyncio.get_running_loop()
            
            # åœ¨çº¿ç¨‹æ± ä¸­å¹¶è¡Œæ‰§è¡Œä¸¤ä¸ªæ¨¡å‹çš„æ¨ç†
            base_result, personal_result = await asyncio.gather(
                loop.run_in_executor(None, lambda: self.transcribe(audio_path, "base")),
                loop.run_in_executor(None, lambda: self.transcribe(audio_path, "personal")),
            )
            
            return base_result, personal_result
        
        # å¦‚æœåœ¨åŒæ­¥ç¯å¢ƒä¸­æ‰§è¡Œ
        import concurrent.futures
        with concurrent.futures.ThreadPoolExecutor() as executor:
            base_result, personal_result = executor.submit(
                lambda: (self.transcribe(audio_path, "base"), 
                         self.transcribe(audio_path, "personal"))
            ).result()
        
        # è®¡ç®—ç»Ÿè®¡åˆ†æ
        text1 = base_result.get("text", "")
        text2 = personal_result.get("text", "")
        
        # è®¡ç®—æ•´ä½“ç½®ä¿¡åº¦
        base_conf = base_result.get("sentences", [])
        personal_conf = personal_result.get("sentences", [])
        
        avg_base_conf = sum(s.get("confidence", 0) for s in base_conf) / len(base_conf) if base_conf else 0
        avg_personal_conf = sum(s.get("confidence", 0) for s in personal_conf) / len(personal_conf) if personal_conf else 0
        
        # è®¡ç®—ç›¸ä¼¼åº¦å’Œ WER
        similarity = self._calculate_similarity(text1, text2)
        wer = self._calculate_wer(text1, text2)
        
        # ç»Ÿè®¡å·®å¼‚
        same_chars = sum(1 for c1, c2 in zip(text1, text2) if c1 == c2)
        diff_chars = abs(len(text1) - len(text2)) + sum(1 for c1, c2 in zip(text1[:min(len(text1), len(text2))], text2[:min(len(text1), len(text2))]) if c1 != c2)
        
        return {
            "base_model": base_result,
            "personal_model": personal_result,
            "statistics": {
                "similarity": round(similarity * 100, 2),  # ç™¾åˆ†æ¯”
                "wer": round(wer * 100, 2),  # Word Error Rate ç™¾åˆ†æ¯”
                "avg_confidence_base": round(avg_base_conf * 100, 2),
                "avg_confidence_personal": round(avg_personal_conf * 100, 2),
                "char_count_base": len(text1),
                "char_count_personal": len(text2),
                "same_chars": same_chars,
                "diff_chars": diff_chars,
                "total_chars": max(len(text1), len(text2)),
            },
            "comparison_timestamp": time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())
        }
